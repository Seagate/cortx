{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "from numpy import vstack\nfrom pandas import read_csv\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch import Tensor\nfrom torch.nn import Linear\nfrom torch.nn import ReLU\nfrom torch.nn import Sigmoid\nfrom torch.nn import Module\nfrom torch.optim import SGD\nfrom torch.nn import BCELoss\nfrom torch.nn.init import kaiming_uniform_\nfrom torch.nn.init import xavier_uniform_", "execution_count": 1, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from cortx_jupyter import read_data, write_data,write_model\n", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Load Data from Cortx"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class CSVDataset(Dataset):\n    def __init__(self, path):\n\n        # Loading data from cortx\n        data = read_data(path)\n        df = read_csv(data, header=None)\n\n        self.X = df.values[:, :-1]\n        self.y = df.values[:, -1]\n\n        self.X = self.X.astype('float32')\n        self.y = LabelEncoder().fit_transform(self.y)\n        self.y = self.y.astype('float32')\n        self.y = self.y.reshape((len(self.y), 1))\n \n    def __len__(self):\n        return len(self.X)\n \n    def __getitem__(self, idx):\n        return [self.X[idx], self.y[idx]]\n \n    def get_splits(self, n_test=0.33):\n        test_size = round(n_test * len(self.X))\n        train_size = len(self.X) - test_size\n        return random_split(self, [train_size, test_size])", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def prepare_data(path):\n    dataset = CSVDataset(path)\n    train, test = dataset.get_splits()\n    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n    return train_dl, test_dl", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Defining the Model"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class MLP(Module):\n    def __init__(self, n_inputs):\n        super(MLP, self).__init__()\n        self.hidden1 = Linear(n_inputs, 10)\n        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n        self.act1 = ReLU()\n        self.hidden2 = Linear(10, 8)\n        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n        self.act2 = ReLU()\n        self.hidden3 = Linear(8, 1)\n        xavier_uniform_(self.hidden3.weight)\n        self.act3 = Sigmoid()\n \n    def forward(self, X):\n        X = self.hidden1(X)\n        X = self.act1(X)\n        X = self.hidden2(X)\n        X = self.act2(X)\n        X = self.hidden3(X)\n        X = self.act3(X)\n        return X", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model Training"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def train_model(train_dl, model):\n    criterion = BCELoss()\n    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n    for epoch in range(100):\n        for i, (inputs, targets) in enumerate(train_dl):\n            optimizer.zero_grad()\n            yhat = model(inputs)\n            loss = criterion(yhat, targets)\n            loss.backward()\n            optimizer.step()", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model Evaluation"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n\ndef evaluate_model(test_dl, model):\n    predictions, actuals = list(), list()\n    for i, (inputs, targets) in enumerate(test_dl):\n        yhat = model(inputs)\n        yhat = yhat.detach().numpy()\n        actual = targets.numpy()\n        actual = actual.reshape((len(actual), 1))\n        yhat = yhat.round()\n        predictions.append(yhat)\n        actuals.append(actual)\n    predictions, actuals = vstack(predictions), vstack(actuals)\n    acc = accuracy_score(actuals, predictions)\n    return acc", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model Prediction"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def predict(row, model):\n    row = Tensor([row])\n    yhat = model(row)\n    yhat = yhat.detach().numpy()\n    return yhat\n \npath = 'ionosphere.csv'\ntrain_dl, test_dl = prepare_data(path)\nprint(len(train_dl.dataset), len(test_dl.dataset))\nmodel = MLP(34)\ntrain_model(train_dl, model)\nacc = evaluate_model(test_dl, model)\nprint('Accuracy: %.3f' % acc)\nrow = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\nyhat = predict(row, model)\nprint('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "path downloading notebooks/test/ionosphere.csv\n235 116\nAccuracy: 0.940\nPredicted: 0.997 (class=1)\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python37464bitd04ad80605dc4165a042c77f86d6bacf", "display_name": "Python 3.7.4 64-bit", "language": "python"}, "language_info": {"name": "python", "version": "3.7.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}