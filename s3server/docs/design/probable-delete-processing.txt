Facts:
-----
- There are 2 mero services we are using,
  ios - for object operations
  kvs - cas/dix - for KVS operations
- There can be following failure scenarios in S3 operations
  F1: ios down,   kvs up
  F2: ios up,     kvs down
  F3: ios down,   kvs down

Assumptions:
-----------
- Each running S3 instance will have a (LC) Lifecycle counter/identifier unique
  instance identifier (uuid) during lifetime
  of S3 process. When process restarts, LC will be regenerated.
- Each probable delete record will have LC attribute. When backgrounddelete
  sees that record LC value is different than instances LC, it means process
  working on the request has restarted, so object is not operated on.
- Background delete process needs a way to identify if request is not
  in-progress, i.e. object is not being operated on currently.
  Probable delete record will have "forceDelete" flag to indicate this.
- old-oid when found in probable delete record, and latest object metadata has
  different OID, it indicates old-oid is 100% candidate for delete, as lastest
  metadata will never have old-oid.
- object version entry putkv operation and object metadata update putkv
  operations are done in sequence within a request, so time gap between these
  2 operations should be in few micro seconds, so we assume if the time
  difference is more than 5 mins or an hour, request has failed between these 2
  putkv operations.
- Probable delete record key to be changed so has to have unique record per
  parallel request if any: New Key = <current oid> - <new oid>
  example: oid1 - oid2 and oid1 - oid3
  We use hyphen '-' as the separator as its bas64 safe, oids are serialised
  using base64 encoding.

Inferences:
----------
- F1 scenarios can be handled by having "forceDelete" flag updated in KVS.
- F2 & F3 scenarios can be handled by
  -- updating LC
  -- Checking latest metadata inconsistencies w.r.t probable delete record.
  -- Checking version entry metadata inconsistencies w.r.t probable delete
     record.


Algorithm:
---------
Assuming schedule interval of 15 mins.
Quickest checks to be done first. Quickest checks are that required least KVS
lookups.

1. If probable delete record is too recent, not more than 14 mins old, ignore
   record for next cycle. (optimisation as likely object may be operated on)
   ** Producer step **

Here onwards ** Consumer steps **
2. If probable delete record has (F1 failures)
   forceDelete = True  (Indicates write complete - PUT obj done with metadata update,
                     or request abandoned due to ios failure)
   Delete object for sure, as S3 has indicated intent and may have failed
   in-between. Delete probable record.

Here onwards F2 & F3 failures (forceDelete = False)
3. For old-oid OLD object.
   If latest object metadata OID is different than old-oid then
     object has transitioned to another object, delete old-oid object,
     delete version entry and delete probable record.
   ELSE
     If LC is same then,
       object may is operated on, so ignore to next schedule cycle.
     else
       process working on request has died without updating latest metadata,
       so delete probable record.

4. For new-oid NEW Object.
    If latest Object metadata OID is equal new-oid then
      new-oid is the current object.

      "Parallel upload leaks" can be handled by looking at version table listing
      for current object.

      For each entry in version list for current object name o1/
           If version entry too recent then
              Skip/Ignore version entry and process in next schedule cycle.
           ELSE
             If version entry is not latest object metadata then
               Delete the object and version entry as its a stale/leaked object.
             else
               It is latest object, ignore and process next record.
      Delete probable record, new-oid is current object.
    Else
      latest object metadata oid is not equal to new-oid
      Check if request is in progress.
      If new-oid is present in version table then
        This indicates write was complete. Check if metadata update is in-progress.
        If version table entry is too recent, less than 5 mins old then
           Metadata update is likely in progress, give it some time, ignore the
           record to be processed in next cycle.
        ELSE
           Version table entry was done, but latest metadata update failed.
           S3 client perspective this object was never live.
           Delete new-oid object, delete probable record.
      ELSE
        new-oid not present in version table.
        IF LC has changed then.
           S3 process working on new-oid has died without updates to metadata.
           new-oid can be safely deleted, delete probable record.
        else
            S3 process is working on new-oid. Ignore the record to be processed
            in next schedule cycle.
