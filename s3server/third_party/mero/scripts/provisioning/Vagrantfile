# -*- mode: ruby -*-
# vi: set ft=ruby :

#
# Helpers
#

# Vagrant doesn't expose information about current virtualisation provider
# through it's public API, so we use our own preferred providers order as a hint
# and try to pick the first available when it's not possible to detect a
# provider from env or CLI arg
def guess_provider()
  host = RbConfig::CONFIG['host_os']

  case host
  when /darwin/
    vmware     = '/Applications/VMware Fusion.app'
    virtualbox = '/Applications/VirtualBox.app'
    return Dir.exists?(vmware) &&
           Vagrant.has_plugin?('vagrant-vmware-fusion')    ? :vmware_fusion
           : Dir.exists?(vmware) &&
             Vagrant.has_plugin?('vagrant-vmware-desktop') ? :vmware_desktop
           : Dir.exists?(virtualbox)                       ? :virtualbox
           :                                                 nil
  when /linux/
    kvm        = '/usr/bin/kvm'
    virtualbox = '/usr/bin/virtualbox'
    return File.exists?(kvm) &&
           Vagrant.has_plugin?('vagrant-libvirt')   ? :libvirt
           : File.exists?(virtualbox)               ? :virtualbox
           :                                          nil
  when /mingw/i
    hyperv = 'C:\\Program Files\\Hyper-V\\'
    virtualbox = 'C:\\Program Files\\Oracle\\VirtualBox\\'
    return Dir.exists?(hyperv)       ? :hyperv
           : Dir.exists?(virtualbox) ? :virtualbox
           :                           nil
  end

  return :virtualbox
end

#
# Global vars
#

MERO_TOP_SRC_DIR = '../..'  # assuming we are in 'mero/scripts/provisioning/.'

# detect provider, this information is used further for provider-specific
# workarounds
PROVIDER =
  if ARGV[1] && ARGV[1].match(/^--provider/)
    case ARGV[1]
    when /^--provider=([^\s]+)$/
      $1.to_sym
    when '--provider'
      ARGV[2].to_sym
    end
  else
    (ENV['VAGRANT_DEFAULT_PROVIDER'] || guess_provider).to_sym
  end

$box = 'centos/7'
$box_version  # latest available version will be used by default

# All Vagrant configuration is done below. The "2" in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don't change it unless you know what
# you're doing.

Vagrant.configure('2') do |config|

  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Plugins ---------------------------------------------------------------
  #

  # The 'vagrant-env' plugin, if installed, allows to control VMs provisioning
  # with an '.env' file.  For example, instead of specifying env parameters
  # every time in a command line like the following:
  #
  #   M0_VM_SSU_NR=5 M0_VM_CLIENT_NR=3 vagrant up
  #
  # One can save them in '.env' file in the directory alongside Vagrantfile:
  #
  #   cat <<EOF > .env
  #   M0_VM_SSU_NR=5
  #   M0_VM_CLIENT_NR=3
  #   EOF
  #
  # And then just do:
  #
  #   vagrant up
  #
  # A complete list of supported variables can be obtained by grepping this
  # file:
  #
  #   grep -oE '\bM0_\w+\b' Vagrantfile | sort -u
  #
  # Or using `./scripts/m0vg list-params`
  #
  config.env.enable if Vagrant.has_plugin?('vagrant-env')

  if Vagrant.has_plugin?('vagrant-hostmanager')
    config.hostmanager.enabled = false
    config.hostmanager.manage_host = false
    config.hostmanager.manage_guest = true
    # use custom IP resolution to workaround incorrect guest VM IP detection,
    # by default 'vagrant-hostmanager' on VirtualBox resolves it as 127.0.0.1
    if PROVIDER == :virtualbox and Vagrant.has_plugin?('vagrant-vbguest')
      config.hostmanager.ip_resolver = proc do |vm, resolving_vm|
        # in VirtualBox 0 is nat, 1 is private network
        vm.provider.driver.read_guest_ip(1)
      end
    end
  end

  # Basic options ---------------------------------------------------------
  #

  ansible_skip_tags = [ 'debuginfo', 'nfs-client', 'nfs-server', 's3server', 'vault-release', 'xperior' ]

  # A box is a minimal clean VM image. You can search for boxes at
  # https://vagrantcloud.com, or even create your own with https://www.packer.io
  $box = ENV['M0_VM_BOX'] if !ENV['M0_VM_BOX'].nil?
  config.vm.box = $box
  config.vm.box_url = ENV['M0_VM_BOX_URL'] if !ENV['M0_VM_BOX_URL'].nil?

  # It's possible to specify particular version of a box to get an older
  # release. For example, for 'centos/7' it can be something like '1610.01'.
  # See https://app.vagrantup.com/centos/boxes/7
  $box_version = ENV['M0_VM_BOX_VERSION'] if !ENV['M0_VM_BOX_VERSION'].nil?
  if !$box_version.nil?
    config.vm.box_version = $box_version
    # restrict system upgrade to the CentOS-Vault release closest to specified
    # box version
    ansible_skip_tags.delete('vault-release')
  end

  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`.
  config.vm.box_check_update = false

  # Networking -----------------------------

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing "localhost:8080" will access port 80 on the guest machine.
  #config.vm.network "forwarded_port", guest: 80, host: 8080

  # Create a private network, which allows host-only access to the machine(s)
  # and between machines, machine access to internet is performed via NAT.
  config.vm.network :private_network, type: :dhcp

  # Shared folders -------------------------

  # Disable default sharing of current folder unless ansible_local provisioner
  # is requested
  if RbConfig::CONFIG['host_os'] !~ /mingw/i &&
     (ENV['M0_VM_PROVISION_WITH_ANSIBLE_LOCAL'].nil? ||
      ENV['M0_VM_PROVISION_WITH_ANSIBLE_LOCAL'].match(/no|false|0/i))
    config.vm.synced_folder '.', '/vagrant', disabled: true
  else
    config.vm.synced_folder '.', '/vagrant',
                            type: 'rsync',
                            rsync__exclude: [ '.git/', '.vagrant/', 'disk*' ],
                            rsync__args: ['--archive', '--delete', '-z']
  end

  # Providers ------------------------------

  # providers priority order (from top to bottom)
  config.vm.provider :vmware_fusion
  config.vm.provider :libvirt
  config.vm.provider :hyperv
  config.vm.provider :virtualbox

  # Machines ==============================================================
  #

  # define additional VM object attributes:
  #   used later to refer to the VM by name known to Vagrant
  config.vm.class.module_eval { attr_accessor :vgname}

  # common host OS info
  host = RbConfig::CONFIG['host_os']
  cpus = host =~ /darwin/ ? `sysctl -n hw.ncpu`.to_i
       : host =~ /linux/  ? `nproc`.to_i
       :                    1
  hostname_prefix = ENV['M0_VM_HOSTNAME_PREFIX'].nil? ? '' : "#{ENV['M0_VM_HOSTNAME_PREFIX']}-"

  # CMU ------------------------------------

  cmu_cpus   = ENV['M0_VM_CMU_CPUS'].nil?   ? (cpus > 2 ? cpus / 2 + 1 : 1) : ENV['M0_VM_CMU_CPUS'].to_i
  cmu_mem    = ENV['M0_VM_CMU_MEM_MB'].nil? ? 3072 : ENV['M0_VM_CMU_MEM_MB'].to_i
  cmu_docker = ENV['M0_VM_CMU_ENABLE_DOCKER'].nil?                 ? false
             : ENV['M0_VM_CMU_ENABLE_DOCKER'].match(/yes|true|1/i) ? true
             :                                                       false

  if !ENV['M0_VM_CMU_ENABLE_NFS_SERVER'].nil? &&
      ENV['M0_VM_CMU_ENABLE_NFS_SERVER'].match(/yes|true|1/i)
    ansible_skip_tags.delete('nfs-client')
    ansible_skip_tags.delete('nfs-server')
  end

  config.vm.define :cmu, primary: true do |cmu|
    cmu.vm.vgname = 'cmu'
    cmu.vm.hostname = "#{hostname_prefix}cmu"
    setup(cmu, cmu_cpus, cmu_mem)
    setup_shared_mero_src_dir(cmu)

    if RbConfig::CONFIG['host_os'] =~ /mingw/i &&
       !provisioned?(cmu.vm.hostname) &&
       ENV['M0_VM_BOX_URL'].nil?
      cmu.vm.synced_folder '.', '/vagrant', type: 'smb'
    end

    if !ENV['M0_VM_CMU_ENABLE_PUBLIC_NET'].nil? &&
        ENV['M0_VM_CMU_ENABLE_PUBLIC_NET'].match(/yes|true|1/i)
      if !ENV['M0_VM_CMU_BRIDGE_INTERFACE'].nil?
        if !ENV['M0_VM_CMU_BRIDGE_STATIC_IP'].nil?
          cmu.vm.network :public_network,
            bridge: ENV['M0_VM_CMU_BRIDGE_INTERFACE'],
            dev: ENV['M0_VM_CMU_BRIDGE_INTERFACE'],
            ip: ENV['M0_VM_CMU_BRIDGE_STATIC_IP']
        else
          cmu.vm.network :public_network,
            bridge: ENV['M0_VM_CMU_BRIDGE_INTERFACE'],
            dev: ENV['M0_VM_CMU_BRIDGE_INTERFACE']
        end
      else
        cmu.vm.network 'public_network'
      end
    end

    if cmu_docker
      cmu.vm.provision :docker
    end

    if !ENV['M0_VM_PROVISION_SCRIPT'].nil?
      if File.exists?(File.expand_path(ENV['M0_VM_PROVISION_SCRIPT']))
        cmu.vm.provision :shell, path: ENV['M0_VM_PROVISION_SCRIPT'], privileged: false
      else
        warn '*** WARNING ***: skipping non-existing custom provisioning script' \
             " M0_VM_PROVISION_SCRIPT=#{ENV['M0_VM_PROVISION_SCRIPT']}"
      end
    end
  end

  # SSUs -----------------------------------

  ssu_nr        = ENV['M0_VM_SSU_NR'].nil?           ? 2    : ENV['M0_VM_SSU_NR'].to_i
  ssu_cpus      = ENV['M0_VM_SSU_CPUS'].nil?         ? (cpus > 2 ? cpus / 3 + 1 : 1) : ENV['M0_VM_SSU_CPUS'].to_i
  ssu_mem       = ENV['M0_VM_SSU_MEM_MB'].nil?       ? 2048 : ENV['M0_VM_SSU_MEM_MB'].to_i
  ssu_disks     = ENV['M0_VM_SSU_DISKS'].nil?        ? 6    : ENV['M0_VM_SSU_DISKS'].to_i
  ssu_disk_size = ENV['M0_VM_SSU_DISK_SIZE_GB'].nil? ? 2    : ENV['M0_VM_SSU_DISK_SIZE_GB'].to_i

  (1..ssu_nr).each do |i|
    config.vm.define "ssu#{i}", autostart: false do |ssu|
      ssu.vm.vgname = "ssu#{i}" # used later to refer to the VM by name known to Vagrant
      ssu.vm.hostname = "#{hostname_prefix}ssu#{i}"
      setup(ssu, ssu_cpus, ssu_mem, ssu_disks, ssu_disk_size)
      setup_shared_mero_src_dir(ssu)
    end
  end

  # Clients --------------------------------

  client_nr   = ENV['M0_VM_CLIENT_NR'].nil?     ? 1    : ENV['M0_VM_CLIENT_NR'].to_i
  client_cpus = ENV['M0_VM_CLIENT_CPUS'].nil?   ? (cpus > 2 ? cpus / 2 : 1) : ENV['M0_VM_CLIENT_CPUS'].to_i
  client_mem  = ENV['M0_VM_CLIENT_MEM_MB'].nil? ? 1024 : ENV['M0_VM_CLIENT_MEM_MB'].to_i

  (1..client_nr).each do |i|
    config.vm.define "client#{i}", autostart: false do |client|
      client.vm.vgname = "client#{i}" # used later to refer to the VM by name known to Vagrant
      client.vm.hostname = "#{hostname_prefix}client#{i}"
      setup(client, client_cpus, client_mem)
      setup_shared_mero_src_dir(client)
    end
  end

  # POD simulation -------------------------

  if !ENV['M0_VM_POD_SIMULATION'].nil? &&
      ENV['M0_VM_POD_SIMULATION'].match(/yes|true|1/i)
    pod_nr        = ENV['M0_VM_POD_NR'].nil?           ? 2    : ENV['M0_VM_POD_NR'].to_i
    pod_cpus      = ENV['M0_VM_POD_CPUS'].nil?         ? (cpus > 2 ? cpus / 3 + 1 : 1) : ENV['M0_VM_POD_CPUS'].to_i
    pod_mem       = ENV['M0_VM_POD_MEM_MB'].nil?       ? 3072 : ENV['M0_VM_POD_MEM_MB'].to_i
    pod_disks     = ENV['M0_VM_POD_DISKS'].nil?        ? 2    : ENV['M0_VM_POD_DISKS'].to_i
    pod_disk_size = ENV['M0_VM_POD_DISK_SIZE_GB'].nil? ? 2    : ENV['M0_VM_POD_DISK_SIZE_GB'].to_i

    disks_dir = !ENV['M0_VM_POD_DISKS_DIR'].nil?          ?  ENV['M0_VM_POD_DISKS_DIR']
              : RbConfig::CONFIG['host_os'] =~ /mingw/i   ?  '../..'
              :                                              '.'

    # since we're are using virtual drives that are shared among all pod-c* VMs,
    # they only need to be created once, thus we have a separate configuration
    # for pod-c1 which is responsible for drive images generation, other pod-c*
    # VM will just attach those virtual drives
    config.vm.define "pod-c1", autostart: false do |pod|
      pod.vm.vgname = "pod-c1" # used later to refer to the VM by name known to Vagrant
      pod.vm.hostname = "#{hostname_prefix}pod-c1"
      setup(pod, pod_cpus, pod_mem)
      setup_shared_mero_src_dir(pod)

      # generate disk images
      #   TODO: add support for VMware and Libvirt, factor out into a function
      pod.vm.provider :virtualbox do |vbox|
        (1..pod_disks).each do |j|
          disk_file = File.expand_path(disks_dir).to_s + "/disk_pod_#{j}.vdi"
          if !File.exist?(disk_file)
            vbox.customize ['createmedium', 'disk', '--filename', disk_file,
                            '--variant', 'Fixed', '--size', pod_disk_size * 1024]
          end
          vbox.customize ['storageattach', :id, '--storagectl', 'sata-controller',
                          '--port', j - 1, '--device', 0, '--type', 'hdd',
                          '--mtype', 'shareable', '--medium', disk_file]
        end
      end
    end

    # remaining pod-c* VMs that attach virtual drives from pod-c1
    (2..pod_nr).each do |i|
      config.vm.define "pod-c#{i}", autostart: false do |pod|
        pod.vm.vgname = "pod-c#{i}" # used later to refer to the VM by name known to Vagrant
        pod.vm.hostname = "#{hostname_prefix}pod-c#{i}"
        setup(pod, pod_cpus, pod_mem)
        setup_shared_mero_src_dir(pod)

        # attach shareable drives
        pod.vm.provider :virtualbox do |vbox|
          (1..pod_disks).each do |j|
            disk_file = File.expand_path(disks_dir).to_s + "/disk_pod_#{j}.vdi"
            vbox.customize ['storageattach', :id, '--storagectl', 'sata-controller',
                            '--port', j - 1, '--device', 0, '--type', 'hdd',
                            '--mtype', 'shareable', '--medium', disk_file]
          end
        end
      end
    end
  end

  # Making pre-provisioned boxes -----------

  if !ENV['M0_VM_BOX_BUILDER_MODE'].nil? &&
      ENV['M0_VM_BOX_BUILDER_MODE'].match(/yes|true|1/i)
    config.vm.define :devbox, autostart: false do |devbox|
      devbox.vm.vgname = 'devbox' # used later to refer to the VM by name known to Vagrant
      devbox.vm.hostname = 'devbox'
      # don't remove default Vagrant ssh key
      devbox.ssh.insert_key = false
      setup(devbox, cpus > 2 ? cpus / 2 + 1 : 1, 6144)
      setup_shared_mero_src_dir(devbox)

      devbox.vm.provision :ansible do |ansible|
        ansible.compatibility_mode = '2.0'
        ansible.playbook = 'vagrant-box-dev.yml'
        #if !ENV['M0_VM_SSH_KEY_FILE'].nil?
        #  ansible.groups['all:vars']['ssh_master_pub_key_file'] = ENV['M0_VM_SSH_KEY_FILE']
        #end
        #ansible.skip_tags = ansible_skip_tags.reject{|i| i == 'vault-release'}.clone
        ansible.skip_tags = ansible_skip_tags
      end
    end
  end

  # Provisioning ==========================================================
  #

  # Ansible --------------------------------

  verbose_provision = ENV['M0_VM_VERBOSE_PROVISION'].nil?                 ? false
                    : ENV['M0_VM_VERBOSE_PROVISION'].match(/yes|true|1/i) ? true
                    :                                                       false

  if !ENV['M0_VM_ENABLE_DEBUGINFO_PKGS'].nil? &&
      ENV['M0_VM_ENABLE_DEBUGINFO_PKGS'].match(/yes|true|1/i)
    ansible_skip_tags.delete('debuginfo')
  end

  if !ENV['M0_VM_ENABLE_S3SERVER'].nil? &&
      ENV['M0_VM_ENABLE_S3SERVER'].match(/yes|true|1/i)
    ansible_skip_tags.delete('s3server')
  end

  if !ENV['M0_VM_ENABLE_XPERIOR'].nil? &&
      ENV['M0_VM_ENABLE_XPERIOR'].match(/yes|true|1/i)
    ansible_skip_tags.delete('xperior')
  end

  if !ENV['M0_VM_FIX_MANPAGES'].nil? &&
      ENV['M0_VM_FIX_MANPAGES'].match(/no|false|0/i)
    ansible_skip_tags.push('recover-man-pages')
  end

  if RbConfig::CONFIG['host_os'] =~ /mingw/i ||
      !ENV['M0_VM_PROVISION_WITH_ANSIBLE_LOCAL'].nil? &&
      ENV['M0_VM_PROVISION_WITH_ANSIBLE_LOCAL'].match(/yes|true|1/i)
    ansible_mode = :ansible_local
    ansible_skip_tags.push('reboot')
  else
    ansible_mode = :ansible
  end

  # delegate OS configuration to Ansible
  if ENV['M0_VM_BOX_BUILDER_MODE'].nil? ||
     ENV['M0_VM_BOX_BUILDER_MODE'].match(/no|false|0/i)
    config.vm.provision ansible_mode do |ansible|
        ansible.compatibility_mode = '2.0'
        ansible.playbook = 'cluster.yml'
        ansible.groups = {
          'clients'  => ["client[1:#{client_nr}]"],
          'ssus'     => ["ssu[1:#{ssu_nr}]"],
          'all:vars' => {
            'm0vg_hostname_prefix' => hostname_prefix,
          },
        }

        if !ENV['M0_VM_POD_SIMULATION'].nil? &&
            ENV['M0_VM_POD_SIMULATION'].match(/yes|true|1/i)
          ansible.groups['clients'].push("pod-c[1:#{pod_nr}]")
          if !ENV['M0_VM_POD_DISKS'].nil?
            ansible.groups['all:vars']['iscsi_fileio_img_num'] = ENV['M0_VM_POD_DISKS']
          end
          if !ENV['M0_VM_POD_DISK_SIZE_GB'].nil?
            ansible.groups['all:vars']['iscsi_fileio_img_size'] = "#{ENV['M0_VM_POD_DISK_SIZE_GB']}g"
          end
        end

        if !ENV['M0_VM_EXTRA_PKGS'].nil?
          ansible.groups['all:vars']['extra_tools_pkgs'] = ENV['M0_VM_EXTRA_PKGS']
        end

        ansible.skip_tags = ansible_skip_tags
        # enable verbose status for each provisioning task
        ansible.verbose  = verbose_provision
    end

    if Vagrant.has_plugin?('vagrant-hostmanager')
      config.vm.provision :hostmanager, run: 'always'
    end
  end
end # config

# there is no proper way of checking in Vagrantfile if VM has been already
# provisioned or not, besides this hack: https://stackoverflow.com/a/38203497
def provisioned?(vm_name)
  vg_dotfile_prefix =
    ENV['VAGRANT_DOTFILE_PATH'].nil? ? '' : ENV['VAGRANT_DOTFILE_PATH'] + '/'
  File.exist?("#{vg_dotfile_prefix}.vagrant/machines/#{vm_name}/#{PROVIDER}/action_provision")
end

def setup(node, cpu_nr, mem_mb, disk_nr = 0, disk_size = 1)
  vm_prefix = $box.split('/')[0]
  if !$box_version.nil?
    vm_prefix += '_' + $box_version
  end

  if !ENV['M0_VM_NAME_PREFIX'].nil?
      vm_prefix = ENV['M0_VM_NAME_PREFIX'] + "_#{vm_prefix}"
  end

  enable_gui = ENV['M0_VM_ENABLE_GUI'].nil?                 ? false
             : ENV['M0_VM_ENABLE_GUI'].match(/yes|true|1/i) ? true
             :                                                false

  # Libvirt/kvm ----------------------------
  #

  node.vm.provider :libvirt do |v|
    # machine name prefix
    v.default_prefix = vm_prefix

    v.cpus   = cpu_nr
    v.memory = mem_mb

    # fine-tune CPU features available to VM
    #v.cpu_mode = 'host-passthrough'

    # cache all VM's IO in memory as much as available
    v.volume_cache = 'unsafe'

    if !ENV['M0_VM_LIBVIRT_STORAGE_POOL'].nil?
        v.storage_pool_name = ENV['M0_VM_LIBVIRT_STORAGE_POOL']
    end

    # disks
    (1..disk_nr).each do
      v.storage :file, :size => "#{disk_size}G", :cache => 'unsafe'
    end
  end

  # Virtualbox -----------------------------
  #

  # directory where to keep serial console logs
  console_log_dir = ENV['M0_VM_CONSOLE_LOG_DIR'].nil? ? '.' : ENV['M0_VM_CONSOLE_LOG_DIR']

  # directory where to keep additional storage disk images for SSU machines
  disks_dir = !ENV['M0_VM_SSU_DISKS_DIR'].nil?          ?  ENV['M0_VM_SSU_DISKS_DIR']
            : RbConfig::CONFIG['host_os'] =~ /mingw/i   ?  '../..'
            :                                              '.'

  node.vm.provider :virtualbox do |v|
    # visible machine name
    v.name = vm_prefix + '_' + node.vm.vgname

    v.gui    = enable_gui
    v.cpus   = cpu_nr
    v.memory = mem_mb

    # re-use master VM disk as copy-on-write base image
    v.linked_clone = true

    # serial console file
    v.customize ['modifyvm', :id, '--uart1', '0x3F8', 4, '--uartmode1', 'file',
                File.expand_path(console_log_dir).to_s + "/console_#{node.vm.vgname}.log"]

    if not provisioned?(node.vm.vgname)
      # sata controller
      v.customize ['storagectl', :id, '--name', 'sata-controller', '--add', 'sata']
      # delay guest-additions installation until VM is fully provisioned if a
      # specific box version requested, otherwise incorrect kernel headers
      # would be installed and guest-additions fail to build
      if Vagrant.has_plugin?('vagrant-vbguest') and !$box_version.nil?
        node.vbguest.no_install = true
      end
    end

    # disks
    (1..disk_nr).each do |i|
      disk_file = File.expand_path(disks_dir).to_s + "/disk_#{node.vm.vgname}_#{i}.vdi"

      if !File.exist?(disk_file)
        v.customize ['createmedium', 'disk', '--filename', disk_file,
                     '--size', disk_size * 1024]
      end
      v.customize ['storageattach', :id, '--storagectl', 'sata-controller',
                   '--port', i - 1, '--device', 0, '--type', 'hdd',
                   '--medium', disk_file]
    end
  end

  # VMware Fusion --------------------------
  #

  node.vm.provider :vmware_fusion do |v|
    # visible machine name
    v.vmx['displayName'] = vm_prefix + '_' + node.vm.vgname

    # show VM's window
    v.gui = enable_gui

    v.vmx['numvcpus'] = cpu_nr
    v.vmx['memsize']  = mem_mb

    # re-use master VM disk as copy-on-write base image
    v.linked_clone = true

    # serial console file
    v.vmx['serial0.fileType'] = 'file'
    v.vmx['serial0.fileName'] = File.expand_path(console_log_dir).to_s +
                                "/console_#{node.vm.vgname}.log"
    v.vmx['serial0.present']  = 'TRUE'

    # network
    #   try to uncomment the following line to disable Vagrant's warning about
    #   overwriting VMX settings (NOTE: VM's network may stop working after that)
    v.whitelist_verified = true
    # workaround incorrect IP address detection by vagrant-hostmanager plugin
    v.ssh_info_public = true
    # a workaround for VMware networking settings in newer Vagrant versions,
    # try to uncomment the following lines if network doesn't work in your
    # combination of VMware/Vagrant versions
    #v.vmx['ethernet0.pcislotnumber'] = 32
    #v.vmx['ethernet1.pcislotnumber'] = 33

    # disks
    vdiskmanager = '/Applications/VMware Fusion.app/Contents/Library/vmware-vdiskmanager'
    if PROVIDER == :vmware_fusion and File.exist?(vdiskmanager)
      (1..disk_nr).each do |i|
        disk_file = File.expand_path(disks_dir).to_s + "/disk_#{node.vm.vgname}_#{i}.vmdk"
        if !File.exists?(disk_file)
          `"#{vdiskmanager}" -c -s #{disk_size}GB -a lsilogic -t 0 #{disk_file}`
        end
        v.vmx["scsi0:#{i}.filename"] = disk_file
        v.vmx["scsi0:#{i}.present"]  = 'TRUE'
        v.vmx["scsi0:#{i}.redo"]     = ''
      end
    end
  end

  # Hyper-v -----------------------------
  #

  node.vm.provider :hyperv do |v|
    # visible machine name
    v.vmname = vm_prefix + '_' + node.vm.vgname

    v.cpus   = cpu_nr
    v.memory = mem_mb

    # re-use master VM disk as copy-on-write base image
    v.linked_clone = true

    # this guard is required because otherwise Vagrant will try to evaluate
    # `powershell ...` commands on Linux and MacOS, which obviously don't
    # have Powershell available and it will produce lots of noise on terminal
    if PROVIDER == :hyperv
      # list provisioned virtual machines
      vms = `powershell "Get-VM | Select-Object Name"`
      # add disks to provisioned virtual machines only
      # disks are added on reload
      if vms.include?(v.vmname)
        (1..disk_nr).each do |i|
          disk_file = File.expand_path(disks_dir).to_s + "/disk_#{node.vm.vgname}_#{i}.vhdx"
          if !File.exist?(disk_file)
            `powershell New-VHD -SizeBytes #{disk_size}GB -Path #{disk_file}`
          end
          is_attached = (`powershell "Get-VHD -Path #{disk_file} | Select-Object -ExpandProperty Attached"`).gsub(/[^A-Za-z]/, '')
          if is_attached == "False"
            `powershell Add-VMHardDiskDrive -VMName #{v.vmname} -Path #{disk_file} -ControllerType SCSI -ControllerNumber 0 -ControllerLocation #{i}`
          end
        end
      end
    end
  end
end

def setup_shared_provider_dir(config, src_path)
  if PROVIDER == :vmware_fusion and $box == 'centos/7'
    # There is an issue with VMware tools on Centos7 which prevents Vagrant from
    # auto-configuring VMware shared dir so we fall back to the manual method
    config.vm.provider :vmware_fusion do |v|
      v.vmx['hgfs.mapRootShare'] = 'TRUE'
      v.vmx['hgfs.linkRootShare'] = 'TRUE'
      v.vmx['sharedFolder0.present'] = 'TRUE'
      v.vmx['sharedFolder0.enabled'] = 'TRUE'
      v.vmx['sharedFolder0.readAccess'] = 'TRUE'
      v.vmx['sharedFolder0.writeAccess'] = 'TRUE'
      v.vmx['sharedFolder0.hostPath'] = src_path
      v.vmx['sharedFolder0.guestName'] = 'data'
      v.vmx['sharedFolder0.expiration'] = 'never'
      v.vmx['sharedFolder.maxNum'] = '1'
      v.vmx['isolation.tools.hgfs.disable'] = 'FALSE'
    end
    config.vm.provision :shell, inline: 'rpm -qi open-vm-tools || yum install -y open-vm-tools'
    config.vm.provision :shell, inline: '[[ -d /data ]] || mkdir /data'
    config.vm.provision :shell,
      inline: 'echo ".host:data  /data  fuse.vmhgfs-fuse  allow_other,auto_unmount,uid=1000,gid=1000  0 0" >> /etc/fstab'
  elsif PROVIDER == :virtualbox and Vagrant.has_plugin?('vagrant-vbguest') and
        !$box_version.nil? and !provisioned?(config.vm.vgname)
    warn "*** WARNING ***: to enable provider-specific sharing you'll need to" \
         " restart the VM using `vagrant reload`"
  else
    config.vm.synced_folder src_path, '/data'
  end
end

def setup_shared_rsync_dir(config, src_path, auto_sync: false)
  config.vm.synced_folder src_path, '/data',
                          type: 'rsync',
                          rsync__exclude: '.git/',
                          rsync__auto: auto_sync,
                          rsync__args: ['--archive', '--delete', '-z']
end

def setup_shared_nfs_dir(config, src_path)
  # Virtualbox is know to have an issue with NFS provisioning for machines w/o
  # static IP address ("No guest IP was given to the Vagrant core NFS helper")
  # or w/o guest additions installed.
  # Reference: https://github.com/mitchellh/vagrant/issues/7070
  if PROVIDER == :virtualbox and !Vagrant.has_plugin?('vagrant-vbguest')
    warn "*** WARNING ***: NFS sharing can't be configured automatically" \
         " for '#{PROVIDER}' provider, you'll need to enable it manually" \
         " after machine is up or install 'vbguest' plugin with" \
         " `vagrant plugin install vagrant-vbguest` and do `vagrant reload`"
  # disable 'vbguest' because it would install latest packages which would
  # make it impossible to downgrade to a specific CentOS-Vault repository
  # during provisioning
  elsif PROVIDER == :virtualbox and !$box_version.nil? and
                                    !provisioned?(config.vm.vgname)
    warn "*** WARNING ***: to enable NFS sharing you'll need to restart the" \
         " VM using `vagrant reload`"
  else
    # MacOS doesn't provide NFSv4, on linux host it should be available though
    nfs_version = RbConfig::CONFIG['host_os'] =~ /linux/ ? 4 : 3
    if !ENV['M0_VM_NFS_VERSION'].nil?
      nfs_version = ENV['M0_VM_NFS_VERSION']
    end

    config.vm.synced_folder src_path, '/data',
                            type: 'nfs',
                            nfs_udp: false,
                            nfs_version: nfs_version,
                            mount_options: ['soft', 'actimeo=1', 'async']
  end
end

# share a top-level project dir (one level up from mero src dir)
def setup_shared_mero_src_dir(config)
  if ARGV[0] and ARGV[0].match(/^(?:up|provision|reload)$/)
    # by default, shared directory is one level up from MERO_TOP_SRC_DIR,
    # it can be customized via M0_VM_SHARED_DIR environment variable
    path = !ENV['M0_VM_SHARED_DIR'].nil? ? File.expand_path(ENV['M0_VM_SHARED_DIR'])
         :                                 File.expand_path(MERO_TOP_SRC_DIR + '/..')
    type = ENV['M0_VM_SHARE_TYPE'] ||
           RbConfig::CONFIG['host_os'] =~ /mingw/i ? 'provider' : 'nfs'

    case type
    when 'provider'
      setup_shared_provider_dir(config, path)
    when 'rsync'
      setup_shared_rsync_dir(config, path)
    when 'rsync-auto'
      setup_shared_rsync_dir(config, path, auto_sync: true)
    when 'none'
      puts "==> #{config.vm.vgname}: shared dir is disabled (M0_VM_SHARE_TYPE=none)"
    else # nfs is used by default
      setup_shared_nfs_dir(config, path)
    end
  end
end

